{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition with timestamps with vosk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import wave\n",
    "import json\n",
    "\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "# !pip install vosk\n",
    "import Word\n",
    "\n",
    "SetLogLevel(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a vosk model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading your vosk model '../models/vosk-model-en-us-0.21'...\n",
      "'../models/vosk-model-en-us-0.21' model was successfully read\n"
     ]
    }
   ],
   "source": [
    "# path to vosk model downloaded from\n",
    "# https://alphacephei.com/vosk/models\n",
    "model_path = \"../models/vosk-model-en-us-0.21\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Please download the model from https://alphacephei.com/vosk/models and unpack as {model_path}\")\n",
    "    sys.exit()\n",
    "\n",
    "print(f\"Reading your vosk model '{model_path}'...\")\n",
    "model = Model(model_path)\n",
    "print(f\"'{model_path}' model was successfully read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the file name to recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the audio file to recognize\n",
    "audio_filename = \"../audio/speech_recognition_systems.wav\"\n",
    "# name of the text file to write recognized text\n",
    "text_filename = \"../audio/speech_recognition_systems_vosk_with_timestamps.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading your file '../audio/speech_recognition_systems.wav'...\n",
      "'../audio/speech_recognition_systems.wav' file was successfully read\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(audio_filename):\n",
    "    print(f\"File '{audio_filename}' doesn't exist\")\n",
    "    sys.exit()\n",
    "\n",
    "print(f\"Reading your file '{audio_filename}'...\")\n",
    "wf = wave.open(audio_filename, \"rb\")\n",
    "print(f\"'{audio_filename}' file was successfully read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if audio is mono wav\n",
    "if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "    print(\"Audio file must be WAV format mono PCM.\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = KaldiRecognizer(model, wf.getframerate())\n",
    "rec.SetWords(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# recognize speech using vosk model\n",
    "while True:\n",
    "    data = wf.readframes(4000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if rec.AcceptWaveform(data):\n",
    "        part_result = json.loads(rec.Result())\n",
    "        results.append(part_result)\n",
    "\n",
    "part_result = json.loads(rec.FinalResult())\n",
    "results.append(part_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results` - list of json dictionaries, each of them has the following structure:\n",
    "\n",
    "```\n",
    "{'result': [\n",
    "  # first word in a sentence\n",
    "  {'conf': 0.84, # confidence\n",
    "   'end': 4.5, # end time\n",
    "   'start': 4.05, # start time\n",
    "   'word': 'test'},\n",
    "  # then, same parameters for \n",
    "  # the second word in a sentence\n",
    "  {'conf': 0.87, \n",
    "   'end': 5.7, \n",
    "   'start': 5.1, \n",
    "   'word': 'library'},\n",
    "  ... ], # and so on \n",
    " # and a full text of the sentence\n",
    " 'text': 'test library ...'}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'result': [{'conf': 1.0, 'end': 1.92, 'start': 1.47, 'word': 'some'},\n",
       "   {'conf': 1.0, 'end': 2.4, 'start': 1.92, 'word': 'speech'},\n",
       "   {'conf': 1.0, 'end': 3.09, 'start': 2.4, 'word': 'recognition'},\n",
       "   {'conf': 1.0, 'end': 4.02, 'start': 3.09, 'word': 'systems'},\n",
       "   {'conf': 1.0, 'end': 4.8, 'start': 4.08, 'word': 'require'},\n",
       "   {'conf': 1.0, 'end': 5.67, 'start': 4.92, 'word': 'training'},\n",
       "   {'conf': 1.0, 'end': 6.9, 'start': 6.03, 'word': 'alphago'},\n",
       "   {'conf': 0.720008, 'end': 7.95, 'start': 6.93, 'word': 'enrollment'},\n",
       "   {'conf': 0.739668, 'end': 8.7, 'start': 8.34, 'word': 'burn'},\n",
       "   {'conf': 1.0, 'end': 9.42, 'start': 8.7, 'word': 'individual'},\n",
       "   {'conf': 1.0, 'end': 10.17, 'start': 9.42, 'word': 'speaker'},\n",
       "   {'conf': 0.670045, 'end': 10.68, 'start': 10.23, 'word': 'reads'},\n",
       "   {'conf': 1.0, 'end': 11.34, 'start': 10.689899, 'word': 'text'},\n",
       "   {'conf': 0.987625, 'end': 11.7, 'start': 11.37, 'word': 'or'},\n",
       "   {'conf': 1.0, 'end': 12.48, 'start': 11.73, 'word': 'isolated'},\n",
       "   {'conf': 1.0, 'end': 13.41, 'start': 12.48, 'word': 'vocabulary'},\n",
       "   {'conf': 1.0, 'end': 13.77, 'start': 13.44, 'word': 'into'},\n",
       "   {'conf': 1.0, 'end': 13.95, 'start': 13.77, 'word': 'the'},\n",
       "   {'conf': 1.0, 'end': 14.55, 'start': 13.95, 'word': 'system'},\n",
       "   {'conf': 1.0, 'end': 15.36, 'start': 15.15, 'word': 'the'},\n",
       "   {'conf': 1.0, 'end': 15.9, 'start': 15.36, 'word': 'system'},\n",
       "   {'conf': 1.0, 'end': 16.86, 'start': 15.93, 'word': 'analyzes'},\n",
       "   {'conf': 1.0, 'end': 17.1, 'start': 16.89, 'word': 'the'},\n",
       "   {'conf': 0.852506, 'end': 17.55, 'start': 17.1, 'word': 'person'},\n",
       "   {'conf': 1.0, 'end': 18.24, 'start': 17.558849, 'word': 'specific'},\n",
       "   {'conf': 1.0, 'end': 18.87, 'start': 18.24, 'word': 'voice'},\n",
       "   {'conf': 1.0, 'end': 19.41, 'start': 19.17, 'word': 'and'},\n",
       "   {'conf': 1.0, 'end': 19.89, 'start': 19.41, 'word': 'use'},\n",
       "   {'conf': 1.0, 'end': 20.16, 'start': 19.89, 'word': 'it'}],\n",
       "  'text': 'some speech recognition systems require training alphago enrollment burn individual speaker reads text or isolated vocabulary into the system the system analyzes the person specific voice and use it'},\n",
       " {'result': [{'conf': 1.0, 'end': 20.73, 'start': 20.52, 'word': 'to'},\n",
       "   {'conf': 0.987695, 'end': 21.12, 'start': 20.73, 'word': 'fine'},\n",
       "   {'conf': 0.987695, 'end': 21.509308, 'start': 21.12, 'word': 'tune'},\n",
       "   {'conf': 0.964927, 'end': 21.66, 'start': 21.51, 'word': 'the'},\n",
       "   {'conf': 1.0, 'end': 22.53, 'start': 21.66, 'word': 'recognition'},\n",
       "   {'conf': 1.0, 'end': 22.8, 'start': 22.56, 'word': 'of'},\n",
       "   {'conf': 0.530819, 'end': 23.01, 'start': 22.8, 'word': 'the'},\n",
       "   {'conf': 0.771107, 'end': 23.574979, 'start': 23.04, 'word': \"person's\"},\n",
       "   {'conf': 1.0, 'end': 24.21, 'start': 23.574979, 'word': 'speech'},\n",
       "   {'conf': 1.0, 'end': 25.05, 'start': 24.24, 'word': 'resulting'},\n",
       "   {'conf': 1.0, 'end': 25.35, 'start': 25.08, 'word': 'in'},\n",
       "   {'conf': 1.0, 'end': 26.07, 'start': 25.35, 'word': 'increased'},\n",
       "   {'conf': 1.0, 'end': 26.91, 'start': 26.1, 'word': 'accuracy'},\n",
       "   {'conf': 1.0, 'end': 28.35, 'start': 27.48, 'word': 'systems'},\n",
       "   {'conf': 1.0, 'end': 28.59, 'start': 28.35, 'word': 'that'},\n",
       "   {'conf': 1.0, 'end': 28.77, 'start': 28.62, 'word': 'do'},\n",
       "   {'conf': 1.0, 'end': 29.31, 'start': 28.77, 'word': 'not'},\n",
       "   {'conf': 1.0, 'end': 29.76, 'start': 29.31, 'word': 'use'},\n",
       "   {'conf': 1.0, 'end': 30.45, 'start': 29.79, 'word': 'training'},\n",
       "   {'conf': 0.761007, 'end': 30.717166, 'start': 30.48, 'word': 'are'},\n",
       "   {'conf': 1.0, 'end': 31.08, 'start': 30.717166, 'word': 'called'},\n",
       "   {'conf': 1.0, 'end': 31.65, 'start': 31.08, 'word': 'speaker'},\n",
       "   {'conf': 1.0, 'end': 32.58, 'start': 31.65, 'word': 'independent'},\n",
       "   {'conf': 1.0, 'end': 33.36, 'start': 32.58, 'word': 'systems'},\n",
       "   {'conf': 1.0, 'end': 34.77, 'start': 33.87, 'word': 'systems'},\n",
       "   {'conf': 1.0, 'end': 35.19, 'start': 34.83, 'word': 'that'},\n",
       "   {'conf': 1.0, 'end': 35.67, 'start': 35.19, 'word': 'use'},\n",
       "   {'conf': 1.0, 'end': 36.39, 'start': 35.7, 'word': 'training'},\n",
       "   {'conf': 0.59374, 'end': 36.66, 'start': 36.45, 'word': 'are'},\n",
       "   {'conf': 1.0, 'end': 37.14, 'start': 36.66, 'word': 'called'},\n",
       "   {'conf': 1.0, 'end': 37.74, 'start': 37.17, 'word': 'speaker'},\n",
       "   {'conf': 1.0, 'end': 38.67, 'start': 37.74, 'word': 'dependent'}],\n",
       "  'text': \"to fine tune the recognition of the person's speech resulting in increased accuracy systems that do not use training are called speaker independent systems systems that use training are called speaker dependent\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of JSON dictionaries to list of 'Word' objects\n",
    "\n",
    "list_of_words = []\n",
    "for sentence in results:\n",
    "    if len(sentence) == 1:\n",
    "        # sometimes there are bugs in recognition \n",
    "        # and it returns an empty dictionary\n",
    "        # {'text': ''}\n",
    "        continue\n",
    "    for obj in sentence['result']:\n",
    "        w = custom_Word.Word(obj)  # create custom Word object\n",
    "        list_of_Words.append(w)  # and add it to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some                 from 1.47 sec to 1.92 sec, confidence is 100.00%\n",
      "speech               from 1.92 sec to 2.40 sec, confidence is 100.00%\n",
      "recognition          from 2.40 sec to 3.09 sec, confidence is 100.00%\n",
      "systems              from 3.09 sec to 4.02 sec, confidence is 100.00%\n",
      "require              from 4.08 sec to 4.80 sec, confidence is 100.00%\n",
      "training             from 4.92 sec to 5.67 sec, confidence is 100.00%\n",
      "alphago              from 6.03 sec to 6.90 sec, confidence is 100.00%\n",
      "enrollment           from 6.93 sec to 7.95 sec, confidence is 72.00%\n",
      "burn                 from 8.34 sec to 8.70 sec, confidence is 73.97%\n",
      "individual           from 8.70 sec to 9.42 sec, confidence is 100.00%\n",
      "speaker              from 9.42 sec to 10.17 sec, confidence is 100.00%\n",
      "reads                from 10.23 sec to 10.68 sec, confidence is 67.00%\n",
      "text                 from 10.69 sec to 11.34 sec, confidence is 100.00%\n",
      "or                   from 11.37 sec to 11.70 sec, confidence is 98.76%\n",
      "isolated             from 11.73 sec to 12.48 sec, confidence is 100.00%\n",
      "vocabulary           from 12.48 sec to 13.41 sec, confidence is 100.00%\n",
      "into                 from 13.44 sec to 13.77 sec, confidence is 100.00%\n",
      "the                  from 13.77 sec to 13.95 sec, confidence is 100.00%\n",
      "system               from 13.95 sec to 14.55 sec, confidence is 100.00%\n",
      "the                  from 15.15 sec to 15.36 sec, confidence is 100.00%\n",
      "system               from 15.36 sec to 15.90 sec, confidence is 100.00%\n",
      "analyzes             from 15.93 sec to 16.86 sec, confidence is 100.00%\n",
      "the                  from 16.89 sec to 17.10 sec, confidence is 100.00%\n",
      "person               from 17.10 sec to 17.55 sec, confidence is 85.25%\n",
      "specific             from 17.56 sec to 18.24 sec, confidence is 100.00%\n",
      "voice                from 18.24 sec to 18.87 sec, confidence is 100.00%\n",
      "and                  from 19.17 sec to 19.41 sec, confidence is 100.00%\n",
      "use                  from 19.41 sec to 19.89 sec, confidence is 100.00%\n",
      "it                   from 19.89 sec to 20.16 sec, confidence is 100.00%\n",
      "to                   from 20.52 sec to 20.73 sec, confidence is 100.00%\n",
      "fine                 from 20.73 sec to 21.12 sec, confidence is 98.77%\n",
      "tune                 from 21.12 sec to 21.51 sec, confidence is 98.77%\n",
      "the                  from 21.51 sec to 21.66 sec, confidence is 96.49%\n",
      "recognition          from 21.66 sec to 22.53 sec, confidence is 100.00%\n",
      "of                   from 22.56 sec to 22.80 sec, confidence is 100.00%\n",
      "the                  from 22.80 sec to 23.01 sec, confidence is 53.08%\n",
      "person's             from 23.04 sec to 23.57 sec, confidence is 77.11%\n",
      "speech               from 23.57 sec to 24.21 sec, confidence is 100.00%\n",
      "resulting            from 24.24 sec to 25.05 sec, confidence is 100.00%\n",
      "in                   from 25.08 sec to 25.35 sec, confidence is 100.00%\n",
      "increased            from 25.35 sec to 26.07 sec, confidence is 100.00%\n",
      "accuracy             from 26.10 sec to 26.91 sec, confidence is 100.00%\n",
      "systems              from 27.48 sec to 28.35 sec, confidence is 100.00%\n",
      "that                 from 28.35 sec to 28.59 sec, confidence is 100.00%\n",
      "do                   from 28.62 sec to 28.77 sec, confidence is 100.00%\n",
      "not                  from 28.77 sec to 29.31 sec, confidence is 100.00%\n",
      "use                  from 29.31 sec to 29.76 sec, confidence is 100.00%\n",
      "training             from 29.79 sec to 30.45 sec, confidence is 100.00%\n",
      "are                  from 30.48 sec to 30.72 sec, confidence is 76.10%\n",
      "called               from 30.72 sec to 31.08 sec, confidence is 100.00%\n",
      "speaker              from 31.08 sec to 31.65 sec, confidence is 100.00%\n",
      "independent          from 31.65 sec to 32.58 sec, confidence is 100.00%\n",
      "systems              from 32.58 sec to 33.36 sec, confidence is 100.00%\n",
      "systems              from 33.87 sec to 34.77 sec, confidence is 100.00%\n",
      "that                 from 34.83 sec to 35.19 sec, confidence is 100.00%\n",
      "use                  from 35.19 sec to 35.67 sec, confidence is 100.00%\n",
      "training             from 35.70 sec to 36.39 sec, confidence is 100.00%\n",
      "are                  from 36.45 sec to 36.66 sec, confidence is 59.37%\n",
      "called               from 36.66 sec to 37.14 sec, confidence is 100.00%\n",
      "speaker              from 37.17 sec to 37.74 sec, confidence is 100.00%\n",
      "dependent            from 37.74 sec to 38.67 sec, confidence is 100.00%\n"
     ]
    }
   ],
   "source": [
    "for word in list_of_words:\n",
    "    print(word.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tVosk thinks you said:\n",
      "\n",
      "some speech recognition systems require training alphago enrollment burn individual speaker reads text or isolated vocabulary into the system the system analyzes the person specific voice and use it to fine tune the recognition of the person's speech resulting in increased accuracy systems that do not use training are called speaker independent systems systems that use training are called speaker dependent \n"
     ]
    }
   ],
   "source": [
    "# forming a final string from the words\n",
    "text = ''\n",
    "for r in results:\n",
    "    text += r['text'] + ' '\n",
    "\n",
    "print(\"\\tVosk thinks you said:\\n\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving text to '../audio/speech_recognition_systems_vosk_with_timestamps.txt'...\n",
      "Text successfully saved\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving text to '{text_filename}'...\")\n",
    "with open(text_filename, \"w\") as text_file:\n",
    "    text_file.write(text)\n",
    "print(f\"Text successfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
